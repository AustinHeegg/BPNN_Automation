import numpy as np


class BPNeuralNetwork:
    def __init__(self, weights, biases):
        self.weights = weights  # 权重矩阵
        self.biases = biases  # 偏置向量

    def activation_function(self, x):
        """使用 sigmoid 激活函数进行激活."""
        return 1 / (1 + np.exp(-x))

    def forward_propagation(self, inputs):
        """执行前向传播并返回输出层的结果."""
        # 输入层到输入层
        input_layer = inputs
        print("Input Layer is:", input_layer)
        # 第一层（输入层到第一个隐藏层）
        hidden_layer_1 = self.activation_function(np.dot(self.weights[0], inputs.T) + self.biases[0].reshape(-1, 1))
        print("Hidden Layer 1 is:", hidden_layer_1)
        # 第二层（第一个隐藏层到第二个隐藏层）
        hidden_layer_2 = self.activation_function(
            np.dot(self.weights[1], hidden_layer_1) + self.biases[1].reshape(-1, 1))
        print("Hidden Layer 2 is:", hidden_layer_2)
        # 第三层（第二个隐藏层到第三个隐藏层）
        hidden_layer_3 = self.activation_function(
            np.dot(self.weights[2], hidden_layer_2) + self.biases[2].reshape(-1, 1))
        print("Hidden Layer 3 is:", hidden_layer_3)
        # 输出层（第三个隐藏层到输出层）
        output_layer = np.dot(self.weights[3], hidden_layer_3) + self.biases[3].reshape(-1, 1)
        print("Output Layer is:", output_layer)
        output_layer_with_act = output_layer
        print("Output Layer is:", output_layer_with_act)
        # 输出层到输出层
        return output_layer_with_act


if __name__ == "__main__":
    weights = [
        np.array([
            [
                0.5552177429199219,
                0.3084506690502167
            ],
            [
                -0.18946720659732819,
                0.5265006422996521
            ],
            [
                0.3990274965763092,
                -0.32685303688049316
            ],
            [
                0.5718861818313599,
                0.2565523087978363
            ],
            [
                -0.45214220881462097,
                0.2459886074066162
            ],
            [
                0.3289647698402405,
                0.4118783175945282
            ],
            [
                0.16396979987621307,
                -0.5205625891685486
            ],
            [
                -0.44143587350845337,
                -0.3190790116786957
            ]
                ]),
        np.array([
            [
                -0.46281394362449646,
                0.8184362649917603,
                -0.8657218217849731,
                -0.19700996577739716,
                1.3189200162887573,
                -0.17993828654289246,
                -0.4196481704711914,
                0.29384398460388184
            ],
            [
                0.6298850178718567,
                0.5554845929145813,
                -0.22652359306812286,
                0.4287906587123871,
                0.3122742474079132,
                0.5728690028190613,
                -0.4455588459968567,
                -0.6395479440689087
            ],
            [
                -0.5230081677436829,
                -0.08424130082130432,
                -0.6277852654457092,
                -0.42706215381622314,
                0.881938636302948,
                -0.6372628808021545,
                -0.18925820291042328,
                0.9274961948394775
            ],
            [
                -0.4122132360935211,
                0.328380823135376,
                -0.58055180311203,
                -0.060809433460235596,
                0.9992377161979675,
                -0.48028963804244995,
                -0.5025448799133301,
                0.48541638255119324
            ],
            [
                -0.23069022595882416,
                -1.042022466659546,
                0.7449933290481567,
                0.4244628846645355,
                -0.8693341016769409,
                -0.24274078011512756,
                0.7978686690330505,
                -0.12028595805168152
            ],
            [
                -0.3578681945800781,
                -0.9453824758529663,
                0.5449256300926208,
                -0.2512098550796509,
                -0.26915913820266724,
                -0.9095878601074219,
                1.2399202585220337,
                0.8158014416694641
            ],
            [
                -0.7606759667396545,
                -0.16583366692066193,
                -0.014749390073120594,
                -0.9213731288909912,
                0.4333261251449585,
                -1.0472429990768433,
                0.3046407699584961,
                1.010650634765625
            ],
            [
                -0.04665713757276535,
                -0.5045121908187866,
                -0.21544048190116882,
                -0.41584914922714233,
                -0.11868418753147125,
                -0.4547361135482788,
                0.11763695627450943,
                0.687080979347229
            ]
        ]),
        np.array([
            [
                0.28838208317756653,
                0.5361260175704956,
                0.15606893599033356,
                -0.23347069323062897,
                -0.47487205266952515,
                -0.5655925273895264,
                -0.08206380158662796,
                -0.34392693638801575
            ],
            [
                0.8862001299858093,
                -0.3012154996395111,
                0.8534571528434753,
                0.3799246847629547,
                -0.5949993133544922,
                0.21029506623744965,
                0.9607828855514526,
                0.3319852948188782
            ],
            [
                -0.8856918215751648,
                -1.4294795989990234,
                0.24548497796058655,
                -0.2793205976486206,
                0.9758012890815735,
                1.5649840831756592,
                0.9175406694412231,
                0.5409137010574341
            ],
            [
                0.06087915971875191,
                0.7342061400413513,
                -0.17032010853290558,
                -0.33672991394996643,
                -0.0434630811214447,
                -0.9615075588226318,
                -1.0206255912780762,
                -0.14401653409004211
            ],
            [
                1.2356237173080444,
                -0.25386449694633484,
                0.9371716380119324,
                1.0227452516555786,
                -1.023711085319519,
                -0.7014941573143005,
                0.48271799087524414,
                0.16157525777816772
            ],
            [
                0.33410048484802246,
                0.6558912992477417,
                -0.4888474941253662,
                0.25894469022750854,
                -0.4308014512062073,
                -0.9823794960975647,
                -0.6407430171966553,
                -0.479830801486969
            ],
            [
                -1.177916407585144,
                0.10636301338672638,
                -0.8555131554603577,
                -0.9536721110343933,
                1.4682866334915161,
                0.821664571762085,
                -0.5794181227684021,
                -0.12867869436740875
            ],
            [
                -0.5566421747207642,
                0.6837021708488464,
                -0.8299524784088135,
                -0.19599731266498566,
                0.15305356681346893,
                -1.0421651601791382,
                -1.058172345161438,
                0.0008392990566790104
            ]
        ]),
        np.array([
            [
                -0.0377945750951767,
                -1.9923838376998901,
                -0.2613021731376648,
                0.8686608076095581,
                -2.5109972953796387,
                0.5435532331466675,
                2.595041275024414,
                1.7128974199295044
            ],
            [
                0.9647938013076782,
                -0.3715898394584656,
                -3.4075756072998047,
                1.3925819396972656,
                0.8735510110855103,
                1.72311270236969,
                -1.326378345489502,
                1.3875863552093506
            ]
        ])
    ]

    biases = [
        np.array([
                    -0.6267057061195374,
                    0.27554595470428467,
                    0.3379974067211151,
                    0.1301918625831604,
                    -0.18526588380336761,
                    -0.2849595248699188,
                    0.3121005892753601,
                    -0.05509473755955696
                ]),
        np.array([
                    0.054638445377349854,
                    0.07180890440940857,
                    -0.16567131876945496,
                    -0.14333781599998474,
                    0.20421600341796875,
                    0.12144392728805542,
                    -0.05241813510656357,
                    -0.12987884879112244
                ]),
        np.array( [
                    -0.16483497619628906,
                    -0.6271377801895142,
                    -0.5123198628425598,
                    0.38517552614212036,
                    -0.5279369354248047,
                    0.19397087395191193,
                    0.3810310363769531,
                    0.6246659159660339
                ]),
        np.array([
                    -0.0830615982413292,
                    -0.18561556935310364
                ])
    ]

    # 输入数据
    input_data = np.array([
        [2.79893862081549, -0.39932882084621],
        [2.39993491496712, -0.39932882084621],
        [1.99970672260403, -0.39932882084621],
        [1.59940262546915, -0.39932882084621],
        [1.19903781828619, -0.39932882084621],
        [0.799761854932068, - 0.39932882084621],
        [0.39932128487282, -0.39932882084621],
        [0, -0.39932882084621],
        [-0.39932128487282, -0.39932882084621],
        [-0.799761854932068, -0.39932882084621],
        [-1.19903781828619, -0.39932882084621],
        [-1.59940262546915, -0.39932882084621],
        [-1.99970672260403, -0.39932882084621],
        [-2.39993491496712, -0.39932882084621],
        [-2.79893862081549, -0.39932882084621]
    ])

    # 创建 BP 神经网络实例
    bp_nn = BPNeuralNetwork(weights, biases)

    # 对每个输入进行前向传播并输出结果
    outputs = bp_nn.forward_propagation(input_data)

    print("输出结果:")
    print(outputs.T)
